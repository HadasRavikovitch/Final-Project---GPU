{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNZYmHkTlb8o87tiVdRFfdP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HadasRavikovitch/Final-Project---GPU/blob/main/GPU_simplify.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4QXph2IkfX-z"
      },
      "outputs": [],
      "source": [
        "from numba import cuda, jit\n",
        "import numpy as np\n",
        "\n",
        "# just for simple version\n",
        "@cuda.jit\n",
        "def gaussian(d_a, d_b, d_pulse):\n",
        "    d_pulse = d_a * d_b"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from numba import cuda\n",
        "import math\n",
        "import numpy as np\n",
        "\n",
        "# just for simple version\n",
        "@cuda.jit\n",
        "def llg(d_c, d_e, d_llg):\n",
        "    d_result = d_c - d_e"
      ],
      "metadata": {
        "id": "IA9dFFPugWR0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# just for simple version\n",
        "\n",
        "@cuda.jit\n",
        "def simulation(d_a, d_b, d_c, d_e, d_pulse, d_llg, arr_res):\n",
        "    for i in range(5):\n",
        "      gaussian(d_a, d_b, d_pulse)\n",
        "      llgi(d_c, d_e, d_llg)\n",
        "      arr_res[i] = d_pulse * d_llg\n",
        "      print(arr_res[i])"
      ],
      "metadata": {
        "id": "eQkkF3u2ghXg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "from numba import cuda, jit, float32\n",
        "import math\n",
        "import numpy as np\n",
        "import cupy as cp\n",
        "\n",
        "a = np.arange((5),dtype=np.float32)\n",
        "b = np.ones((5,), dtype=np.float32)\n",
        "c = np.zeros((5,), dtype=np.float32)\n",
        "# Fix: Convert e to np.float32 before assigning it to d_e\n",
        "e = np.arange(2,7, dtype=np.float32)\n",
        "\n",
        "d_a = cuda.to_device(a)\n",
        "d_b = cuda.to_device(b)\n",
        "d_c = cuda.to_device(c)\n",
        "d_e = cuda.to_device(e)\n",
        "d_pulse = cuda.device_array((5,), dtype=np.float32)\n",
        "d_llg = cuda.device_array((5,), dtype=np.float32)\n",
        "d_out = cuda.device_array((5,), dtype=np.float32)\n",
        "\n",
        "# just for simple version\n",
        "\n",
        "@cuda.jit\n",
        "def gaussian(d_a, d_b, d_gues):\n",
        "    \"\"\"Calculate element-wise product of d_a and d_b.\"\"\"\n",
        "    idx = cuda.grid(1)\n",
        "    if idx < d_a.shape[0]:\n",
        "      d_gues = d_a[idx] * d_b[idx]\n",
        "\n",
        "@cuda.jit\n",
        "def llg(d_c, d_e, d_llg):\n",
        "  \"\"\"Calculate element-wise difference of d_c and d_e.\"\"\"\n",
        "  idx = cuda.grid(1)\n",
        "  if idx < d_c.shape[0]:\n",
        "    d_llg[idx] = d_c[idx] - d_e[idx]\n",
        "\n",
        "\n",
        "@cuda.jit\n",
        "def simulation(d_a, d_b, d_c, d_e, d_pulse, d_llg, arr_res):\n",
        "      gaussian(d_a, d_b, d_pulse)\n",
        "      llg(d_c, d_e, d_llg)\n",
        "      idx = cuda.grid(1)\n",
        "      if idx < arr_res.shape[0]:\n",
        "        arr_res[idx] = d_pulse[idx] + d_llg[idx]\n",
        "\n",
        "simulation[1, 5](d_a, d_b, d_c, d_e, d_pulse, d_llg, d_out)\n",
        "print(d_out.copy_to_host())"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cv2vWKsIl8Tr",
        "outputId": "620fe833-cb1d-4745-b4b8-653416078369"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: Grid size 1 will likely result in GPU under-utilization due to low occupancy.\n",
            "  warn(NumbaPerformanceWarning(msg))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-2. -3. -4. -5. -6.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from numba import cuda\n",
        "\n",
        "@cuda.jit\n",
        "def cross(array1, array2):\n",
        "  cross_result = cuda.device_array_like(array1)\n",
        "  idx = cuda.grid(1)\n",
        "  if idx < array1.shape[0]:\n",
        "    cross_result[idx][0] = array1[idx][1] * array2[idx][2] - array1[idx][2] * array2[idx][1]\n",
        "    cross_result[idx][1] = array1[idx][2] * array2[idx][0] - array1[idx][0] * array2[idx][2]\n",
        "    cross_result[idx][2] = array1[idx][0] * array2[idx][1] - array1[idx][1] * array2[idx][0]\n",
        "\n",
        "  return cross_result"
      ],
      "metadata": {
        "id": "KuyQ10B-tKTe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "    M0 = np.linalg.norm(M, axis=1, keepdims=True)\n",
        "    gma_LL=gma/((1+alpha**2))\n",
        "    LL_lamda=gma*alpha/(1+alpha**2)\n",
        "    \n",
        "   # Compute LLG terms\n",
        "    an = -gma_LL * miu * np.cross(M, H, axis=1) - (LL_lamda * miu / M0) * np.cross(M, np.cross(M, H, axis=1), axis=1)\n",
        "    \n",
        "    bn = -gma_LL * miu * np.cross(M + (dt / 2) * an, H, axis=1) - (LL_lamda * miu / M0) * np.cross(M + (dt / 2) * an, np.cross(M + (dt / 2) * an, H, axis=1), axis=1)\n",
        "    \n",
        "    cn = -gma_LL * miu * np.cross(M + (dt / 2) * bn, H, axis=1) - (LL_lamda * miu / M0) * np.cross(M + (dt / 2) * bn, np.cross(M + (dt / 2) * bn, H, axis=1), axis=1)\n",
        "    \n",
        "    dn = -gma_LL * miu * np.cross(M + dt * cn, H, axis=1) - (LL_lamda * miu / M0) * np.cross(M + dt * cn, np.cross(M + dt * cn, H, axis=1), axis=1)\n",
        "    \n",
        "    new_M = M + (dt/6)*(an+2*bn+2*cn+dn)\n",
        "    return new_M"
      ],
      "metadata": {
        "id": "nQjfM8O_qlpM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from numba import cuda\n",
        "\n",
        "x = np.array([[1,2,3], [4,5,6]])\n",
        "y = np.array([[4,5,6], [1,7,3]])\n",
        "\n",
        "d_x = cuda.to_device(x)\n",
        "d_y = cuda.to_device(y)\n",
        "d_cross = cuda.device_array_like(d_x)\n",
        "\n",
        "res1= np.cross(x, y, axis=1)\n",
        "print(res1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tTQAGTXefInx",
        "outputId": "7fc28a7c-d7d6-4638-c034-9fafdd820849"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ -3   6  -3]\n",
            " [-27  -6  23]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%timeit np.cross(x, y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ozLWJXWj7yju",
        "outputId": "504bbad6-57eb-4f3f-df7e-3140f60daf35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "29.8 µs ± 5.21 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@cuda.jit\n",
        "def cross(array1, array2, cross_result): # Add cross_result as an output argument\n",
        "  idx = cuda.grid(1)\n",
        "  if idx < array1.shape[0]:\n",
        "    cross_result[idx][0] = array1[idx][1] * array2[idx][2] - array1[idx][2] * array2[idx][1]\n",
        "    cross_result[idx][1] = array1[idx][2] * array2[idx][0] - array1[idx][0] * array2[idx][2]\n",
        "    cross_result[idx][2] = array1[idx][0] * array2[idx][1] - array1[idx][1] * array2[idx][0]"
      ],
      "metadata": {
        "id": "dfhsWy6s7diK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%timeit cross[4, 16](d_x, d_y, d_cross)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GHsHCIao77dm",
        "outputId": "63683827-e744-49d2-b301-6cb44c8b8388"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The slowest run took 4.00 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
            "98.1 µs ± 64.2 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: Grid size 4 will likely result in GPU under-utilization due to low occupancy.\n",
            "  warn(NumbaPerformanceWarning(msg))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "big_arr1 = np.random.rand(100000, 3)\n",
        "big_arr2 = np.random.rand(100000, 3)\n",
        "\n",
        "d_big_arr1 = cuda.to_device(big_arr1)\n",
        "d_big_arr2 = cuda.to_device(big_arr2)\n",
        "d_big_res = cuda.device_array_like(d_big_arr1)\n",
        "\n",
        "#d_big_arr = cross[4,16](d_big_arr1, d_big_arr2, d_big_res)"
      ],
      "metadata": {
        "id": "o7KPXHnS9RrO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%timeit cross[4,16](d_big_arr1, d_big_arr2, d_big_res)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tl_hIIM0-bAz",
        "outputId": "cbcfeb1d-c5bf-4279-98e5-a5163fe4f9d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The slowest run took 4.11 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
            "95.5 µs ± 66.4 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%timeit np.cross(big_arr1, big_arr2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uhRti5hm-rWb",
        "outputId": "ffd26271-530a-4770-b7ee-b9ebe4f73df0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5.44 ms ± 64.8 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# an example\n",
        "import numpy as np\n",
        "from numba import cuda\n",
        "\n",
        "# CPU version\n",
        "@jit(nopython=True)\n",
        "def matriz_mult_cpu(A, B):\n",
        "    result = np.zeros_like(A)\n",
        "    for i in range(A.shape[0]):\n",
        "        for j in range(A.shape[1]):\n",
        "            for k in range(B.shape[1]):\n",
        "                result[i][j] += A[i][k] * B[k][j]\n",
        "    return result\n",
        "\n",
        "# GPU version\n",
        "@cuda.jit\n",
        "def matriz_mult_gpu(A, B, C):\n",
        "    i, j = cuda.grid(2)\n",
        "    if i < C.shape[0] and j < C.shape[1]:\n",
        "        tmp = 0.\n",
        "        for k in range(A.shape[1]):\n",
        "            tmp += A[i, k] * B[k, j]\n",
        "        C[i, j] = tmp\n",
        "\n",
        "# CPU and GPU times\n",
        "times_cpu = []\n",
        "times_gpu = []\n",
        "\n",
        "for N in sizes:\n",
        "    # Create arrays of size NxN\n",
        "    A = np.random.rand(N, N).astype(np.float32)\n",
        "    B = np.random.rand(N, N).astype(np.float32)\n",
        "    C = np.zeros_like(A)\n",
        "\n",
        "    # Calculates CPU time\n",
        "    start_time_cpu = time.time()\n",
        "    C_cpu = matriz_mult_cpu(A, B)\n",
        "    end_time_cpu = time.time()\n",
        "\n",
        "    # Configure the grid and block\n",
        "    threadsperblock = (16, 16)\n",
        "    blockspergrid_x = int(np.ceil(A.shape[0] / threadsperblock[1]))\n",
        "    blockspergrid_y = int(np.ceil(B.shape[1] / threadsperblock[0]))\n",
        "    blockspergrid = (blockspergrid_x, blockspergrid_y)\n",
        "\n",
        "    # Calculates time for GPU\n",
        "    start_time_gpu = time.time()\n",
        "    matriz_mult_gpu[blockspergrid, threadsperblock](A, B, C)\n",
        "    end_time_gpu = time.time()\n",
        "\n",
        "    times_cpu.append(end_time_cpu - start_time_cpu)\n",
        "    times_gpu.append(end_time_gpu - start_time_gpu)\n",
        "\n",
        "# DDraw the times in a chart\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(sizes, times_cpu, marker='o', label='CPU')\n",
        "plt.plot(sizes, times_gpu, marker='o', label='GPU')\n",
        "plt.title('Execution time for matrix multiplication')\n",
        "plt.xlabel('Matrix size')\n",
        "plt.ylabel('Execution time (seconds)')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "UgeOjv0hT3mo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "fea49023-dbd3-453e-d90f-5c4a7ec1b71c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'sizes' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-226667a16ffe>\u001b[0m in \u001b[0;36m<cell line: 29>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mtimes_gpu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mN\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msizes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0;31m# Create arrays of size NxN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'sizes' is not defined"
          ]
        }
      ]
    }
  ]
}