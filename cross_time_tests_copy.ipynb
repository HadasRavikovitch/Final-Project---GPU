{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HadasRavikovitch/Final-Project---GPU/blob/main/cross_time_tests_copy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Er4kQ7qak7i7"
      },
      "source": [
        "LLG Kernel - Basic function to run on GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "m8rF-m9USex7"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from numba import cuda, float64, int64\n",
        "import math\n",
        "\n",
        "len_matrix = (100000,3)\n",
        "len_M0_norm = 100000\n",
        "\n",
        "@cuda.jit(device=True)\n",
        "def cross_product(a, b, result):  # Pass result array as an argument\n",
        "  \"\"\"\n",
        "  Calculates the cross product of two 3D vectors.\n",
        "  \"\"\"\n",
        "  result[0] = a[1] * b[2] - a[2] * b[1]\n",
        "  result[1] = a[2] * b[0] - a[0] * b[2]\n",
        "  result[2] = a[0] * b[1] - a[1] * b[0]\n",
        "  #return result  # No need to return, result is modified in-place\n",
        "\n",
        "@cuda.jit(device=True)\n",
        "def norm(array):  # Pass result array as an argument\n",
        "    x = array[0]\n",
        "    y = array[1]\n",
        "    z = array[2]\n",
        "    return math.sqrt(x**2 + y**2 + z**2)\n",
        "\n",
        "@cuda.jit\n",
        "#def LLG_kernel(array1, array2, dt, alpha, llg_result, M_0, an_res, bn_res, cn_res, dn_res):\n",
        "def LLG_kernel(array1, array2, dt, alpha, llg_result):\n",
        "  llg_gama = gama/((1+alpha**2))\n",
        "  llg_lamda = gama*alpha/(1+alpha**2)\n",
        "\n",
        "  cross1 = cuda.local.array(len_matrix, dtype=float64)  # Allocate cross product result arrays\n",
        "  cross2 = cuda.local.array(len_matrix, dtype=np.float64)\n",
        "  cross12 = cuda.local.array(len_matrix, dtype=np.float64)\n",
        "  cross22 = cuda.local.array(len_matrix, dtype=np.float64)\n",
        "  cross13 = cuda.local.array(len_matrix, dtype=np.float64)\n",
        "  cross23 = cuda.local.array(len_matrix, dtype=np.float64)\n",
        "  cross14 = cuda.local.array(len_matrix, dtype=np.float64)\n",
        "  cross24 = cuda.local.array(len_matrix, dtype=np.float64)\n",
        "  M_norm = cuda.local.array(len_M0_norm, dtype=np.float64)\n",
        "\n",
        "  an = cuda.local.array(len_matrix, dtype=np.float64)\n",
        "  bn = cuda.local.array(len_matrix, dtype=np.float64)\n",
        "  cn = cuda.local.array(len_matrix, dtype=np.float64)\n",
        "  dn = cuda.local.array(len_matrix, dtype=np.float64)\n",
        "\n",
        "  sum_bn = cuda.local.array(len_matrix, dtype=np.float64)\n",
        "  sum_cn = cuda.local.array(len_matrix, dtype=np.float64)\n",
        "  sum_dn = cuda.local.array(len_matrix, dtype=np.float64)\n",
        "\n",
        "  idx = cuda.grid(1)\n",
        "  if idx < array1.shape[0]:\n",
        "    # Calculate M0 (norm) manually\n",
        "    #M_norm[idx] = norm_row(array1[idx])\n",
        "    temp_norm_result = cuda.local.array(1, dtype=float64)\n",
        "    temp_norm_result = norm(array1[idx]) # Call norm_row with two arguments\n",
        "    M_norm[idx] = temp_norm_result\n",
        "\n",
        "    cross_product(array1[idx], array2[idx], cross1[idx])  # Calculate cross products using modified function\n",
        "    cross_product(array1[idx], cross1[idx], cross2[idx])\n",
        "\n",
        "    # Update llg_result directly\n",
        "    # Modify to use element-wise operations:\n",
        "\n",
        "    #an = -gma_LL * miu * np.cross(M, H, axis=1) - (LL_lambda * miu / M0) * np.cross(M, np.cross(M, H, axis=1), axis=1)\n",
        "    #bn = -gma_LL * miu * np.cross(M + (dt / 2) * an, H, axis=1) - (LL_lambda * miu / M0) * np.cross(M + (dt / 2) * an, np.cross(M + (dt / 2) * an, H, axis=1), axis=1)\n",
        "    #cn = -gma_LL * miu * np.cross(M + (dt / 2) * bn, H, axis=1) - (LL_lambda * miu / M0) * np.cross(M + (dt / 2) * bn, np.cross(M + (dt / 2) * bn, H, axis=1), axis=1)\n",
        "    for i in range(3):\n",
        "        an[idx][i] = -llg_gama * miu * cross1[idx][i] - (llg_lamda * miu / M_norm[idx]) * cross2[idx][i]\n",
        "\n",
        "    for i in range(3):\n",
        "        sum_bn[idx][i] = array1[idx][i] + (dt/2) * an[idx][i]\n",
        "\n",
        "    cross_product(sum_bn[idx], array2[idx], cross12[idx])\n",
        "    cross_product(sum_bn[idx], cross12[idx], cross22[idx])\n",
        "\n",
        "    # Modify to use element-wise operations:\n",
        "    for i in range(3):\n",
        "        bn[idx][i] = -llg_gama * miu * cross12[idx][i] - (llg_lamda * miu / M_norm[idx]) * cross22[idx][i]\n",
        "\n",
        "    for i in range(3):\n",
        "        sum_cn[idx][i] = array1[idx][i] + (dt/2) * bn[idx][i]\n",
        "\n",
        "    cross_product(sum_cn[idx], array2[idx], cross13[idx])\n",
        "    cross_product(sum_cn[idx], cross13[idx], cross23[idx])\n",
        "\n",
        "    for i in range(3):\n",
        "        cn[idx][i] = -llg_gama * miu * cross13[idx][i] - (llg_lamda * miu / M_norm[idx]) * cross23[idx][i]\n",
        "\n",
        "    for i in range(3):\n",
        "        sum_dn[idx][i] = array1[idx][i] + (dt) * cn[idx][i]\n",
        "\n",
        "    cross_product(sum_dn[idx], array2[idx], cross14[idx])\n",
        "    cross_product(sum_dn[idx], cross14[idx], cross24[idx])\n",
        "#   dn = -gma_LL * miu * np.cross(M + dt * cn, H, axis=1) - (LL_lambda * miu / M0) * np.cross(M + dt * cn, np.cross(M + dt * cn, H, axis=1), axis=1)\n",
        "\n",
        "    for i in range(3):\n",
        "        dn[idx][i] = -llg_gama * miu * cross14[idx][i] - (llg_lamda * miu / M_norm[idx]) * cross24[idx][i]\n",
        "\n",
        "    for i in range(3):\n",
        "      llg_result[idx][i] = array1[idx][i] + (dt/6)*(an[idx][i] + 2*bn[idx][i] + 2*cn[idx][i] + dn[idx][i])\n",
        "\n",
        "    # FOR DEBUG:\n",
        "    #for i in range(3):\n",
        "      #an_res[idx][i] = an[idx][i]\n",
        "      #bn_res[idx][i] = bn[idx][i]\n",
        "      #cn_res[idx][i] = cn[idx][i]\n",
        "      #dn_res[idx][i] = dn[idx][i]\n",
        "    #M_0[idx] = M_norm[idx]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mf032hXSlHlV"
      },
      "source": [
        "Running the LLG KERNEL for short input arrays (len 3)\n",
        "\n",
        "> Add blockquote\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 634
        },
        "id": "JLWqZmOow4Ch",
        "outputId": "c68adbdf-a82e-4aaf-b329-3600ab95ee11"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "Minor version compatibility requires ptxcompiler and cubinlinker packages to be available",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numba_cuda/numba/cuda/cudadrv/driver.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, max_registers, lineinfo, cc)\u001b[0m\n\u001b[1;32m   2664\u001b[0m         \u001b[0mpassed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mtype\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[0minferred\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mextension\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mA\u001b[0m \u001b[0mLinkableCode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2665\u001b[0;31m         \u001b[0mobject\u001b[0m \u001b[0mrepresents\u001b[0m \u001b[0ma\u001b[0m \u001b[0mfile\u001b[0m \u001b[0malready\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmemory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cubinlinker'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-7ec081852543>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;31m#LLG_kernel[blocks, threadsperblock](d_x, d_y, dt, alpha, d_res, d_M_norm, d_an_res, d_bn_res, d_cn_res, d_dn_res)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m \u001b[0mLLG_kernel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreadsperblock\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_res\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"res:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0md_res\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_to_host\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;31m#print(\"M0:\",d_M_norm.copy_to_host())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numba_cuda/numba/cuda/dispatcher.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    537\u001b[0m             raise ValueError(\"Can't create ForAll with negative task count: %s\"\n\u001b[1;32m    538\u001b[0m                              % ntasks)\n\u001b[0;32m--> 539\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatcher\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdispatcher\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    540\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mntasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mntasks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthread_per_block\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtpb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numba_cuda/numba/cuda/dispatcher.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, args, griddim, blockdim, stream, sharedmem)\u001b[0m\n\u001b[1;32m    679\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_numba_type_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 681\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcuda_types\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCUDADispatcher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    682\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0menable_caching\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numba_cuda/numba/cuda/dispatcher.py\u001b[0m in \u001b[0;36m_compile_for_args\u001b[0;34m(self, *args, **kws)\u001b[0m\n\u001b[1;32m    687\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mconfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgriddim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblockdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msharedmem\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m         \u001b[0mgriddim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblockdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize_kernel_dimensions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgriddim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblockdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 689\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_LaunchConfiguration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgriddim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblockdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msharedmem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numba_cuda/numba/cuda/dispatcher.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self, sig)\u001b[0m\n\u001b[1;32m    932\u001b[0m         \u001b[0mEach\u001b[0m \u001b[0msignature\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mcompiled\u001b[0m \u001b[0monce\u001b[0m \u001b[0mby\u001b[0m \u001b[0mcaching\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mcompiled\u001b[0m \u001b[0mfunction\u001b[0m \u001b[0minside\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m         \u001b[0mthis\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 934\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    935\u001b[0m         \u001b[0mReturns\u001b[0m \u001b[0mthe\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mCompileResult\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    936\u001b[0m         \"\"\"\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numba_cuda/numba/cuda/dispatcher.py\u001b[0m in \u001b[0;36mbind\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnrt_in_asm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m             \u001b[0mnrt_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbasedir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'runtime'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'nrt.cu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m             \u001b[0mlink\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrt_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numba_cuda/numba/cuda/codegen.py\u001b[0m in \u001b[0;36mget_cufunc\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    212\u001b[0m             \u001b[0;31m# `-ptx` flag is meant to view the optimized PTX for LTO objects.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m             \u001b[0;31m# Non-LTO objects are not passed to linker.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_link_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_nonlto\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m             \u001b[0mptx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_linked_ptx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numba_cuda/numba/cuda/codegen.py\u001b[0m in \u001b[0;36mget_cubin\u001b[0;34m(self, cc)\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ltoir_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcc\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mltoir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mltoir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_link_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_nonlto\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numba_cuda/numba/cuda/cudadrv/driver.py\u001b[0m in \u001b[0;36mnew\u001b[0;34m(cls, max_registers, lineinfo, cc)\u001b[0m\n\u001b[1;32m   2574\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2575\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2576\u001b[0;31m     def new(cls,\n\u001b[0m\u001b[1;32m   2577\u001b[0m             \u001b[0mmax_registers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2578\u001b[0m             \u001b[0mlineinfo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numba_cuda/numba/cuda/cudadrv/driver.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, max_registers, lineinfo, cc)\u001b[0m\n\u001b[1;32m   2665\u001b[0m         \u001b[0mobject\u001b[0m \u001b[0mrepresents\u001b[0m \u001b[0ma\u001b[0m \u001b[0mfile\u001b[0m \u001b[0malready\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmemory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2667\u001b[0;31m         \u001b[0mWhen\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mignore_nonlto\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mset\u001b[0m \u001b[0mto\u001b[0m \u001b[0mtrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdo\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0madd\u001b[0m \u001b[0mcode\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mwill\u001b[0m \u001b[0;32mnot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2668\u001b[0m         \u001b[0mbe\u001b[0m \u001b[0mLTO\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0med\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mlinking\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mThis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0museful\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minspecting\u001b[0m \u001b[0mthe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2669\u001b[0m         \u001b[0mLTO\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0med\u001b[0m \u001b[0mportion\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mPTX\u001b[0m \u001b[0mwhen\u001b[0m \u001b[0mlinker\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0madded\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mobjects\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mcan\u001b[0m \u001b[0mbe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: Minor version compatibility requires ptxcompiler and cubinlinker packages to be available",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "import numpy as np\n",
        "from numba import cuda, float64, int64\n",
        "import math\n",
        "\n",
        "#physical parameters\n",
        "eps=8.854e-12 #[F/m]\n",
        "miu=4*np.pi*1e-7 #[H/m]\n",
        "c=1/(eps*miu)**0.5\n",
        "heta = (miu/eps)**0.5\n",
        "q = 1.60217646e-19    # Elementary charge [Coulombs]\n",
        "miu = 4 * np.pi * 1e-7    # Magnetic permeability [H/m]\n",
        "g = 2    # Landau factor\n",
        "me = 9.1093821545e-31    # Electron mass [kg]\n",
        "gma_factor = 1\n",
        "gama = gma_factor * g * q / (2 * me)\n",
        "alpha = 0\n",
        "\n",
        "dz = 2e-9/8\n",
        "dt = 2\n",
        "\n",
        "x = np.array([[1.,2.,3.], [4.,5.,6.], [7.,2.,5.]], dtype = np.float64)\n",
        "#norm_x = np.array(np.linalg.norm(x, axis=1))\n",
        "y = np.array([[4,5,6], [1,7,3], [4,5,6]], dtype = np.float64)\n",
        "M_norm = np.arange(3, dtype=np.float64)\n",
        "#an_res = np.arange(3, dtype=np.float64)\n",
        "#d_x = cuda.to_device(x)\n",
        "#d_y = cuda.to_device(y)\n",
        "res = np.empty_like(x)\n",
        "d_x = cuda.to_device(x)\n",
        "d_y = cuda.to_device(y)\n",
        "d_res = cuda.device_array_like(d_x)\n",
        "\n",
        "# FOR DEBUG - uncomment and print to understand better:\n",
        "#d_an_res = cuda.device_array_like(d_x)\n",
        "#d_bn_res = cuda.device_array_like(d_x)\n",
        "#d_cn_res = cuda.device_array_like(d_x)\n",
        "#d_dn_res = cuda.device_array_like(d_x)\n",
        "#d_M_norm = cuda.device_array_like(M_norm)\n",
        "\n",
        "blocks = 8  # Ensure enough blocks to cover the data\n",
        "threadsperblock = 64 # Ensure enough threads to cover the data\n",
        "\n",
        "# Call the kernel with launch configuration\n",
        "# FOR DEBUG VERSION (with M0, an, bn...):\n",
        "#LLG_kernel[blocks, threadsperblock](d_x, d_y, dt, alpha, d_res, d_M_norm, d_an_res, d_bn_res, d_cn_res, d_dn_res)\n",
        "\n",
        "LLG_kernel[blocks, threadsperblock](d_x, d_y, dt, alpha, d_res)\n",
        "print(\"res:\",d_res.copy_to_host())\n",
        "#print(\"M0:\",d_M_norm.copy_to_host())\n",
        "#print(\"an:\",d_an_res.copy_to_host())\n",
        "#print(\"bn:\",d_bn_res.copy_to_host())\n",
        "#print(\"cn:\",d_cn_res.copy_to_host())\n",
        "#print(\"dn:\",d_dn_res.copy_to_host())"
      ]
    },
    {
      "source": [
        "!nvidia-smi\n",
        "!nvcc --version"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XYvbNwxyECkS",
        "outputId": "f3a7a4f2-e296-40a4-e711-d7a2b283a9ae"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Feb 16 09:21:42 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA L4                      Off |   00000000:00:03.0 Off |                    0 |\n",
            "| N/A   61C    P0             30W /   72W |     215MiB /  23034MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2024 NVIDIA Corporation\n",
            "Built on Thu_Jun__6_02:18:23_PDT_2024\n",
            "Cuda compilation tools, release 12.5, V12.5.82\n",
            "Build cuda_12.5.r12.5/compiler.34385749_0\n"
          ]
        }
      ]
    },
    {
      "source": [
        "!pip install --upgrade numba-cuda"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_6GB-PhMERe5",
        "outputId": "aea98bda-1c44-4a54-d101-ffd0042f0274"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numba-cuda in /usr/local/lib/python3.11/dist-packages (0.4.0)\n",
            "Requirement already satisfied: numba>=0.59.1 in /usr/local/lib/python3.11/dist-packages (from numba-cuda) (0.61.0)\n",
            "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.59.1->numba-cuda) (0.44.0)\n",
            "Requirement already satisfied: numpy<2.2,>=1.24 in /usr/local/lib/python3.11/dist-packages (from numba>=0.59.1->numba-cuda) (2.1.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i0vZL2Cr3d4d",
        "outputId": "1bc8000d-8973-4d6b-d83d-45bc5d1eb394"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/numba_cuda/numba/cuda/dispatcher.py:605: NumbaPerformanceWarning: Grid size 4 will likely result in GPU under-utilization due to low occupancy.\n",
            "  warn(NumbaPerformanceWarning(msg))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "67.7 µs ± 661 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
          ]
        }
      ],
      "source": [
        "%timeit LLG_kernel[4,16](d_x, d_y, dt, alpha, d_res); cuda.synchronize()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!uv pip install -q --system --force-reinstall numba-cuda==0.4.0"
      ],
      "metadata": {
        "id": "d6lg3WALiHNe"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "nsEzUeNWnjVY"
      },
      "outputs": [],
      "source": [
        "from numba import config\n",
        "config.CUDA_ENABLE_PYNVJITLINK = 1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from numba import config\n",
        "config.CUDA_ENABLE_MINOR_VERSION_COMPATIBILITY = True"
      ],
      "metadata": {
        "id": "KWg8aVaPMAry"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJStAI9flRxS"
      },
      "source": [
        "LLG Step - The basic function to run on CPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Vro-bkVrO8i3"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def LLG_step(M: np.array, H: np.array, dt: float, alpha: float) -> np.array:\n",
        "    \"\"\"\n",
        "    \"\"\"\n",
        "    M0 = np.linalg.norm(M, axis=1, keepdims=True)\n",
        "    #print(\"M0:\", M0)\n",
        "    gma_LL=gama/((1+alpha**2))\n",
        "    LL_lambda=gama*alpha/(1+alpha**2)\n",
        "\n",
        "   # Compute LLG terms\n",
        "    an = -gma_LL * miu * np.cross(M, H, axis=1) - (LL_lambda * miu / M0) * np.cross(M, np.cross(M, H, axis=1), axis=1)\n",
        "    #print(\"an:\",an)\n",
        "    bn = -gma_LL * miu * np.cross(M + (dt / 2) * an, H, axis=1) - (LL_lambda * miu / M0) * np.cross(M + (dt / 2) * an, np.cross(M + (dt / 2) * an, H, axis=1), axis=1)\n",
        "    #print(\"bn:\",bn)\n",
        "    cn = -gma_LL * miu * np.cross(M + (dt / 2) * bn, H, axis=1) - (LL_lambda * miu / M0) * np.cross(M + (dt / 2) * bn, np.cross(M + (dt / 2) * bn, H, axis=1), axis=1)\n",
        "    #print(\"cn:\",cn)\n",
        "    dn = -gma_LL * miu * np.cross(M + dt * cn, H, axis=1) - (LL_lambda * miu / M0) * np.cross(M + dt * cn, np.cross(M + dt * cn, H, axis=1), axis=1)\n",
        "    #print(\"dn:\",dn)\n",
        "    new_M = M + (dt/6)*(an+2*bn+2*cn+dn)\n",
        "    return new_M"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mapby7SlW_J"
      },
      "source": [
        "Running the LLG on CPU for short input arrays (len 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pbSUd8U9Pkcl",
        "outputId": "bc88b1ed-540c-4001-e51b-00475b284006"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-6.24733836e+24, -7.34973942e+23,  4.77737052e+24],\n",
              "       [ 1.68011243e+25, -9.76156552e+24,  1.71766114e+25],\n",
              "       [ 3.27066219e+25, -2.27844227e+25, -2.81739568e+24]])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "import numpy as np\n",
        "from numba import cuda\n",
        "import math\n",
        "\n",
        "#physical parameters\n",
        "eps=8.854e-12 #[F/m]\n",
        "miu=4*np.pi*1e-7 #[H/m]\n",
        "c=1/(eps*miu)**0.5\n",
        "heta = (miu/eps)**0.5\n",
        "q = 1.60217646e-19    # Elementary charge [Coulombs]\n",
        "miu = 4 * np.pi * 1e-7    # Magnetic permeability [H/m]\n",
        "g = 2    # Landau factor\n",
        "me = 9.1093821545e-31    # Electron mass [kg]\n",
        "gma_factor = 1\n",
        "gama = gma_factor * g * q / (2 * me)\n",
        "alpha = 0\n",
        "\n",
        "dz = 2e-9/8\n",
        "dt = 2\n",
        "\n",
        "x = np.array([[1.,2.,3.], [4.,5.,6.], [7.,2.,5.]], dtype = np.float64)\n",
        "y = np.array([[4,5,6], [1,7,3], [4,5,6]], dtype = np.float64)\n",
        "#d_x = cuda.to_device(x)\n",
        "#d_y = cuda.to_device(y)\n",
        "res = np.empty_like(x)\n",
        "\n",
        "LLG_step(x, y, dt, alpha)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "83xrcb4EvVC_",
        "outputId": "6961caf1-3811-428a-bb4c-8cdba2adb622"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "363 µs ± 39.5 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
          ]
        }
      ],
      "source": [
        "%timeit LLG_step(x, y, dt, alpha)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "atpvI6lZleIi"
      },
      "source": [
        "Adding the time propogate loop - Where in each iteration there is a call for the LLG Kernel. Suppose to be less time effictiate beacuse in each iterate there is a data transfer for and to host and device."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AO3sVHByncNC",
        "outputId": "03d3886b-df37-4109-e047-edc40f56d8f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "arr1 [[     0      2      4]\n",
            " [     6      8     10]\n",
            " [    12     14     16]\n",
            " ...\n",
            " [599982 599984 599986]\n",
            " [599988 599990 599992]\n",
            " [599994 599996 599998]]\n",
            "arr2 [[     0      1      2]\n",
            " [     3      4      5]\n",
            " [     6      7      8]\n",
            " ...\n",
            " [299991 299992 299993]\n",
            " [299994 299995 299996]\n",
            " [299997 299998 299999]]\n",
            "res: [[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from numba import cuda, float64, int64\n",
        "import math\n",
        "\n",
        "#physical parameters\n",
        "eps=8.854e-12 #[F/m]\n",
        "miu=4*np.pi*1e-7 #[H/m]\n",
        "c=1/(eps*miu)**0.5\n",
        "heta = (miu/eps)**0.5\n",
        "q = 1.60217646e-19    # Elementary charge [Coulombs]\n",
        "miu = 4 * np.pi * 1e-7    # Magnetic permeability [H/m]\n",
        "g = 2    # Landau factor\n",
        "me = 9.1093821545e-31    # Electron mass [kg]\n",
        "gma_factor = 1\n",
        "gama = gma_factor * g * q / (2 * me)\n",
        "alpha = 0\n",
        "dz = 2e-9/8\n",
        "dt = 2\n",
        "\n",
        "big_arr1 = np.arange(0,2*100000*3,2).reshape((100000, 3))\n",
        "big_arr2 = np.arange(100000*3).reshape((100000, 3))\n",
        "\n",
        "time_steps = 100\n",
        "d_big_arr1 = cuda.to_device(big_arr1)\n",
        "d_big_arr2 = cuda.to_device(big_arr2)\n",
        "M_norm = np.empty_like(big_arr1)\n",
        "res = np.empty_like(big_arr1)\n",
        "d_res = cuda.device_array_like(big_arr1)\n",
        "saved_res_for_alltime = np.zeros(shape=(time_steps*100000,3))\n",
        "\n",
        "blocks = 8  # Ensure enough blocks to cover the data\n",
        "threadsperblock = 256 # Ensure enough threads to cover the data\n",
        "\n",
        "\n",
        "print(\"arr1\",big_arr1)\n",
        "print(\"arr2\",big_arr2)\n",
        "print(\"res:\",saved_res_for_alltime)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "5qukFO-kLzY6"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def LLG_in_loop(big_arr1: np.array, big_arr2: np.array, dt: int, alpha: int, blocks: int,\n",
        "                threadsperblock: int ,saved_res_for_alltime: np.array) -> np.array:\n",
        "  d_big_arr1 = cuda.to_device(big_arr1)\n",
        "  d_big_arr2 = cuda.to_device(big_arr2)\n",
        "  for i in range(0,time_steps):\n",
        "    LLG_kernel[blocks, threadsperblock](d_big_arr1, d_big_arr2, dt, alpha, d_res)\n",
        "    print(\"d_res\",d_res.copy_to_host())\n",
        "    saved_res_for_alltime[i*100000, i*100000,i*100000] = d_res.copy_to_host()  # Assign to index i"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 619
        },
        "id": "rmZ8_DXT8q59",
        "outputId": "d30be794-0189-4338-c72e-422954b5c7a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/numba_cuda/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: Grid size 8 will likely result in GPU under-utilization due to low occupancy.\n",
            "  if ntasks < 0:\n",
            "ERROR:numba.cuda.cudadrv.driver:Call to cuLinkAddData results in CUDA_ERROR_UNSUPPORTED_PTX_VERSION\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "LinkerError",
          "evalue": "[222] Call to cuLinkAddData results in CUDA_ERROR_UNSUPPORTED_PTX_VERSION\nptxas application ptx input, line 9; fatal   : Unsupported .version 8.5; current version is '8.4'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mCudaAPIError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numba_cuda/numba/cuda/cudadrv/driver.py\u001b[0m in \u001b[0;36madd_ptx\u001b[0;34m(self, ptx, name)\u001b[0m\n\u001b[1;32m   2806\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2807\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2808\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numba_cuda/numba/cuda/cudadrv/driver.py\u001b[0m in \u001b[0;36msafe_cuda_api_call\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    303\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_ctypes_wrap_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlibfn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m         \u001b[0;31m# Wrap a CUDA driver function by default\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlibfn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numba_cuda/numba/cuda/cudadrv/driver.py\u001b[0m in \u001b[0;36m_check_ctypes_error\u001b[0;34m(self, fname, retcode)\u001b[0m\n\u001b[1;32m    371\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 372\u001b[0;31m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mCudaAPIError\u001b[0m: [222] Call to cuLinkAddData results in CUDA_ERROR_UNSUPPORTED_PTX_VERSION",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mLinkerError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-f59bf94b7d76>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'timeit'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'LLG_in_loop(d_big_arr1, d_big_arr2, dt, alpha, blocks, threadsperblock,saved_res_for_alltime); cuda.synchronize()'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_line_magic\u001b[0;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[1;32m   2416\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'local_ns'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_local_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2417\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2418\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2419\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-53>\u001b[0m in \u001b[0;36mtimeit\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtimeit\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1178\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m                 \u001b[0mnumber\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m                 \u001b[0mtime_number\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtime_number\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtimeit\u001b[0;34m(self, number)\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m             \u001b[0mtiming\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mgcold\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<magic-timeit>\u001b[0m in \u001b[0;36minner\u001b[0;34m(_it, _timer)\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-ad93427d90b9>\u001b[0m in \u001b[0;36mLLG_in_loop\u001b[0;34m(big_arr1, big_arr2, dt, alpha, blocks, threadsperblock, saved_res_for_alltime)\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0md_big_arr2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbig_arr2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtime_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mLLG_kernel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreadsperblock\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_big_arr1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_big_arr2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_res\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"d_res\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0md_res\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_to_host\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0msaved_res_for_alltime\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100000\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md_res\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_to_host\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Assign to index i\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numba_cuda/numba/cuda/dispatcher.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    537\u001b[0m             raise ValueError(\"Can't create ForAll with negative task count: %s\"\n\u001b[1;32m    538\u001b[0m                              % ntasks)\n\u001b[0;32m--> 539\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatcher\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdispatcher\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    540\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mntasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mntasks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthread_per_block\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtpb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numba_cuda/numba/cuda/dispatcher.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, args, griddim, blockdim, stream, sharedmem)\u001b[0m\n\u001b[1;32m    679\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_numba_type_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 681\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcuda_types\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCUDADispatcher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    682\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0menable_caching\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numba_cuda/numba/cuda/dispatcher.py\u001b[0m in \u001b[0;36m_compile_for_args\u001b[0;34m(self, *args, **kws)\u001b[0m\n\u001b[1;32m    687\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mconfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgriddim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblockdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msharedmem\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m         \u001b[0mgriddim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblockdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize_kernel_dimensions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgriddim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblockdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 689\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_LaunchConfiguration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgriddim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblockdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msharedmem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numba_cuda/numba/cuda/dispatcher.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self, sig)\u001b[0m\n\u001b[1;32m    932\u001b[0m         \u001b[0mEach\u001b[0m \u001b[0msignature\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mcompiled\u001b[0m \u001b[0monce\u001b[0m \u001b[0mby\u001b[0m \u001b[0mcaching\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mcompiled\u001b[0m \u001b[0mfunction\u001b[0m \u001b[0minside\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m         \u001b[0mthis\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 934\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    935\u001b[0m         \u001b[0mReturns\u001b[0m \u001b[0mthe\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mCompileResult\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    936\u001b[0m         \"\"\"\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numba_cuda/numba/cuda/dispatcher.py\u001b[0m in \u001b[0;36mbind\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnrt_in_asm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m             \u001b[0mnrt_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbasedir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'runtime'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'nrt.cu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m             \u001b[0mlink\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrt_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numba_cuda/numba/cuda/codegen.py\u001b[0m in \u001b[0;36mget_cufunc\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    212\u001b[0m             \u001b[0;31m# `-ptx` flag is meant to view the optimized PTX for LTO objects.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m             \u001b[0;31m# Non-LTO objects are not passed to linker.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_link_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_nonlto\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m             \u001b[0mptx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_linked_ptx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numba_cuda/numba/cuda/codegen.py\u001b[0m in \u001b[0;36mget_cubin\u001b[0;34m(self, cc)\u001b[0m\n\u001b[1;32m    186\u001b[0m             \u001b[0mlinker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_ltoir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mltoir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m             \u001b[0mptx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_asm_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m             \u001b[0mlinker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_ptx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mptx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numba_cuda/numba/cuda/cudadrv/driver.py\u001b[0m in \u001b[0;36madd_ptx\u001b[0;34m(self, ptx, name)\u001b[0m\n\u001b[1;32m   2808\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2809\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2810\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mLinkerError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{path} not found'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2812\u001b[0m         \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mLinkerError\u001b[0m: [222] Call to cuLinkAddData results in CUDA_ERROR_UNSUPPORTED_PTX_VERSION\nptxas application ptx input, line 9; fatal   : Unsupported .version 8.5; current version is '8.4'"
          ]
        }
      ],
      "source": [
        "%timeit LLG_in_loop(d_big_arr1, d_big_arr2, dt, alpha, blocks, threadsperblock,saved_res_for_alltime); cuda.synchronize()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3NnP13H_AFef",
        "outputId": "7ec05fe0-816a-416f-a2db-887cf04c400f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "arr1 [[     0      2      4]\n",
            " [     6      8     10]\n",
            " [    12     14     16]\n",
            " ...\n",
            " [599982 599984 599986]\n",
            " [599988 599990 599992]\n",
            " [599994 599996 599998]]\n",
            "arr2 [[     0      1      2]\n",
            " [     3      4      5]\n",
            " [     6      7      8]\n",
            " ...\n",
            " [299991 299992 299993]\n",
            " [299994 299995 299996]\n",
            " [299997 299998 299999]]\n",
            "res: [[0 0 0]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " ...\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [0 0 0]]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from numba import cuda, float64, int64\n",
        "import math\n",
        "\n",
        "#physical parameters\n",
        "eps=8.854e-12 #[F/m]\n",
        "miu=4*np.pi*1e-7 #[H/m]\n",
        "c=1/(eps*miu)**0.5\n",
        "heta = (miu/eps)**0.5\n",
        "q = 1.60217646e-19    # Elementary charge [Coulombs]\n",
        "miu = 4 * np.pi * 1e-7    # Magnetic permeability [H/m]\n",
        "g = 2    # Landau factor\n",
        "me = 9.1093821545e-31    # Electron mass [kg]\n",
        "gma_factor = 1\n",
        "gama = gma_factor * g * q / (2 * me)\n",
        "alpha = 0\n",
        "dz = 2e-9/8\n",
        "dt = 2\n",
        "\n",
        "big_arr1 = np.arange(0,2*100000*3,2).reshape((100000, 3))\n",
        "big_arr2 = np.arange(100000*3).reshape((100000, 3))\n",
        "\n",
        "time_steps = 100\n",
        "d_big_arr1 = cuda.to_device(big_arr1)\n",
        "d_big_arr2 = cuda.to_device(big_arr2)\n",
        "M_norm = np.empty_like(big_arr1)\n",
        "res = np.empty_like(big_arr1)\n",
        "d_res = cuda.device_array_like(big_arr1)\n",
        "saved_res_for_alltime = np.zeros(shape=(time_steps,100000,3))\n",
        "\n",
        "blocks = 8  # Ensure enough blocks to cover the data\n",
        "threadsperblock = 256 # Ensure enough threads to cover the data\n",
        "\n",
        "def loop_in_LLG(big_arr1, big_arr2, dt, alpha, blocks, threadsperblock):\n",
        "  d_big_arr1 = cuda.to_device(big_arr1)\n",
        "  d_big_arr2 = cuda.to_device(big_arr2)\n",
        "  for i in range(0,time_steps):\n",
        "    LLG_kernel[blocks, threadsperblock](d_big_arr1, d_big_arr2, dt, alpha, d_res)\n",
        "    saved_res_for_alltime[i, :,:] = d_res.copy_to_host()  # Assign to index i\n",
        "\n",
        "print(\"arr1\",big_arr1)\n",
        "print(\"arr2\",big_arr2)\n",
        "print(\"res:\",d_res.copy_to_host())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "Mg9pqgOYkmIY",
        "outputId": "ca1d4eba-8df4-4805-d3ff-ece2dd6a79e6"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (<ipython-input-13-136d260c1ffc>, line 110)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-13-136d260c1ffc>\"\u001b[0;36m, line \u001b[0;32m110\u001b[0m\n\u001b[0;31m    saved_res_for_alltime[t, :,:] = llg_result[]  # Assign to index i\u001b[0m\n\u001b[0m                                               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from numba import cuda, float64, int64\n",
        "import math\n",
        "\n",
        "len_matrix = (100000,3)\n",
        "len_M0_norm = 100000\n",
        "\n",
        "@cuda.jit(device=True)\n",
        "def cross_product(a, b, result):  # Pass result array as an argument\n",
        "  \"\"\"\n",
        "  Calculates the cross product of two 3D vectors.\n",
        "  \"\"\"\n",
        "  result[0] = a[1] * b[2] - a[2] * b[1]\n",
        "  result[1] = a[2] * b[0] - a[0] * b[2]\n",
        "  result[2] = a[0] * b[1] - a[1] * b[0]\n",
        "  #return result  # No need to return, result is modified in-place\n",
        "\n",
        "@cuda.jit(device=True)\n",
        "def norm(array):  # Pass result array as an argument\n",
        "    x = array[0]\n",
        "    y = array[1]\n",
        "    z = array[2]\n",
        "    return math.sqrt(x**2 + y**2 + z**2)\n",
        "\n",
        "@cuda.jit\n",
        "#def LLG_kernel(array1, array2, dt, alpha, llg_result, M_0, an_res, bn_res, cn_res, dn_res):\n",
        "def Loop_in_LLG_kernel(array1, array2, dt, alpha, llg_result, n_times):\n",
        "  for t in range(0, n_times):\n",
        "    llg_gama = gama/((1+alpha**2))\n",
        "    llg_lamda = gama*alpha/(1+alpha**2)\n",
        "\n",
        "    cross1 = cuda.local.array(len_matrix, dtype=float64)  # Allocate cross product result arrays\n",
        "    cross2 = cuda.local.array(len_matrix, dtype=np.float64)\n",
        "    cross12 = cuda.local.array(len_matrix, dtype=np.float64)\n",
        "    cross22 = cuda.local.array(len_matrix, dtype=np.float64)\n",
        "    cross13 = cuda.local.array(len_matrix, dtype=np.float64)\n",
        "    cross23 = cuda.local.array(len_matrix, dtype=np.float64)\n",
        "    cross14 = cuda.local.array(len_matrix, dtype=np.float64)\n",
        "    cross24 = cuda.local.array(len_matrix, dtype=np.float64)\n",
        "    M_norm = cuda.local.array(len_M0_norm, dtype=np.float64)\n",
        "\n",
        "    an = cuda.local.array(len_matrix, dtype=np.float64)\n",
        "    bn = cuda.local.array(len_matrix, dtype=np.float64)\n",
        "    cn = cuda.local.array(len_matrix, dtype=np.float64)\n",
        "    dn = cuda.local.array(len_matrix, dtype=np.float64)\n",
        "\n",
        "    sum_bn = cuda.local.array(len_matrix, dtype=np.float64)\n",
        "    sum_cn = cuda.local.array(len_matrix, dtype=np.float64)\n",
        "    sum_dn = cuda.local.array(len_matrix, dtype=np.float64)\n",
        "\n",
        "    idx = cuda.grid(1)\n",
        "    if idx < array1.shape[0]:\n",
        "      # Calculate M0 (norm) manually\n",
        "      #M_norm[idx] = norm_row(array1[idx])\n",
        "      temp_norm_result = cuda.local.array(1, dtype=float64)\n",
        "      temp_norm_result = norm(array1[idx]) # Call norm_row with two arguments\n",
        "      M_norm[idx] = temp_norm_result\n",
        "\n",
        "      cross_product(array1[idx], array2[idx], cross1[idx])  # Calculate cross products using modified function\n",
        "      cross_product(array1[idx], cross1[idx], cross2[idx])\n",
        "\n",
        "      # Update llg_result directly\n",
        "      # Modify to use element-wise operations:\n",
        "\n",
        "      #an = -gma_LL * miu * np.cross(M, H, axis=1) - (LL_lambda * miu / M0) * np.cross(M, np.cross(M, H, axis=1), axis=1)\n",
        "      #bn = -gma_LL * miu * np.cross(M + (dt / 2) * an, H, axis=1) - (LL_lambda * miu / M0) * np.cross(M + (dt / 2) * an, np.cross(M + (dt / 2) * an, H, axis=1), axis=1)\n",
        "      #cn = -gma_LL * miu * np.cross(M + (dt / 2) * bn, H, axis=1) - (LL_lambda * miu / M0) * np.cross(M + (dt / 2) * bn, np.cross(M + (dt / 2) * bn, H, axis=1), axis=1)\n",
        "      for i in range(3):\n",
        "          an[idx][i] = -llg_gama * miu * cross1[idx][i] - (llg_lamda * miu / M_norm[idx]) * cross2[idx][i]\n",
        "\n",
        "      for i in range(3):\n",
        "          sum_bn[idx][i] = array1[idx][i] + (dt/2) * an[idx][i]\n",
        "\n",
        "      cross_product(sum_bn[idx], array2[idx], cross12[idx])\n",
        "      cross_product(sum_bn[idx], cross12[idx], cross22[idx])\n",
        "\n",
        "      # Modify to use element-wise operations:\n",
        "      for i in range(3):\n",
        "          bn[idx][i] = -llg_gama * miu * cross12[idx][i] - (llg_lamda * miu / M_norm[idx]) * cross22[idx][i]\n",
        "\n",
        "      for i in range(3):\n",
        "          sum_cn[idx][i] = array1[idx][i] + (dt/2) * bn[idx][i]\n",
        "\n",
        "      cross_product(sum_cn[idx], array2[idx], cross13[idx])\n",
        "      cross_product(sum_cn[idx], cross13[idx], cross23[idx])\n",
        "\n",
        "      for i in range(3):\n",
        "          cn[idx][i] = -llg_gama * miu * cross13[idx][i] - (llg_lamda * miu / M_norm[idx]) * cross23[idx][i]\n",
        "\n",
        "      for i in range(3):\n",
        "          sum_dn[idx][i] = array1[idx][i] + (dt) * cn[idx][i]\n",
        "\n",
        "      cross_product(sum_dn[idx], array2[idx], cross14[idx])\n",
        "      cross_product(sum_dn[idx], cross14[idx], cross24[idx])\n",
        "  #   dn = -gma_LL * miu * np.cross(M + dt * cn, H, axis=1) - (LL_lambda * miu / M0) * np.cross(M + dt * cn, np.cross(M + dt * cn, H, axis=1), axis=1)\n",
        "\n",
        "      for i in range(3):\n",
        "          dn[idx][i] = -llg_gama * miu * cross14[idx][i] - (llg_lamda * miu / M_norm[idx]) * cross24[idx][i]\n",
        "\n",
        "      for i in range(3):\n",
        "        llg_result[idx][i] = array1[idx][i] + (dt/6)*(an[idx][i] + 2*bn[idx][i] + 2*cn[idx][i] + dn[idx][i])\n",
        "\n",
        "    # FOR DEBUG:\n",
        "    #for i in range(3):\n",
        "      #an_res[idx][i] = an[idx][i]\n",
        "      #bn_res[idx][i] = bn[idx][i]\n",
        "      #cn_res[idx][i] = cn[idx][i]\n",
        "      #dn_res[idx][i] = dn[idx][i]\n",
        "    #M_0[idx] = M_norm[idx]\n",
        "  saved_res_for_alltime[t, :,:] = llg_result[]  # Assign to index i"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Ns7NctnRInW5"
      },
      "outputs": [],
      "source": [
        "def pulse_gen(max_feald: float, fea : float, FWHM: float, dt : float ,lamda = 800e-9 , teta = 0, start_sefty = 4 ):\n",
        "    \"\"\"\n",
        "    input-\n",
        "\n",
        "    \"\"\"\n",
        "    # move to time w\n",
        "    w = 2* np.pi * c/lamda\n",
        "    teta -= np.pi/4\n",
        "    turn_m= np.array([np.cos(teta) , -np.sin(teta), np.sin(teta) ,np.cos(teta) ])\n",
        "    turn_m = turn_m.reshape((2,2))\n",
        "    pulse = max_feald * turn_m @ np.array([1 ,np.exp(-fea*1j)]).reshape(2)\n",
        "    sigma = ((0.5/np.log(2))** 0.5) * FWHM\n",
        "    peak_location = start_sefty*sigma\n",
        "\n",
        "    def out_pulse(n: int) -> np.array:\n",
        "        \"\"\"\n",
        "        input-\n",
        "        :patam n: index of step in time\n",
        "        :return: 2D comlmx np.array of the inject pulse (E_x E_y) in this time step\n",
        "        \"\"\"\n",
        "        r = pulse  * np.exp(- (n*dt - peak_location)**2/( 2*sigma**2))* np.exp(1j*w*n*dt)\n",
        "        return r\n",
        "    return out_pulse\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lx3SZCAY5fzO"
      },
      "outputs": [],
      "source": [
        "# magnets matirals proprety\n",
        "\n",
        "# cobalt\n",
        "Co_er = 1\n",
        "Co_sigma = 1.7e7 #https://periodictable.com/Elements/027/data.html\n",
        "Co_er_complex= -16 + 23.3j\n",
        "\n",
        "# Iron\n",
        "Fe_er = 1\n",
        "Fe_sigma = 1e7\n",
        "\n",
        "# nical\n",
        "Ni_er = 1\n",
        "Ni_sigma = 1.4e7 #https://periodictable.com/Elements/027/data.html\n",
        "\n",
        "alpae_renge = (0.025 ,0.0025) # genral range\n",
        "gilbert_damping_time = 600e-12 # [sec] artical - concting to alpha in {I dont remmber how}\n",
        "precession_frequency = 8.5e9 #[Hz] artical\n",
        "\n",
        "# aditinal matirals proprety\n",
        "Pt_er = 1\n",
        "Pt_sigma = 7e6 # [1/oham*m]\n",
        "\n",
        "Au_er = 1\n",
        "Au_sigma = 1e6 # (spintronics lab)\n",
        "\n",
        "\n",
        "alpha = {\"Co_Au\" : 0.02, \"Co_Pt\" : 0.025 , \"Fe_Au\": 0.02, \"Fe_Pt\" : 0.025, \"Ni_Au\": 0.05, \"Ni_Pt\" : 0.06}\n",
        "\n",
        "key_name = [\n",
        "            \"H times picture\",\n",
        "            \"E times picture\",\n",
        "            \"ms time picture\",\n",
        "            \"time picture\",\n",
        "            \"H in locations\",\n",
        "            \"E in locations\",\n",
        "            \"ms in locations\",\n",
        "            \"locations\",\n",
        "            \"time intervals\",\n",
        "            \"matitral location\", \"e_r\" ,\"conductivity\", \"gilbert damping factor\",\"initial magnetization\",\n",
        "            \"max magnetic field\" ,\"polarization phase\",\"pulse width (FWHM)\",\n",
        "            \"systen status\", \"dt\", \"safety_start\"\n",
        "            ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "daGBSMp_5fzQ"
      },
      "outputs": [],
      "source": [
        "# pulse proprty (in the article)\n",
        "mean_wave_lenght= 784e-9 # [m]\n",
        "# B_opt =  [0.02, 0.2 ] # [T]\n",
        "# FWHM = 1.1e-12 #[sec]\n",
        "FWHM = 1.1e-12 #[sec]\n",
        "B_opt =2.4e5 #[A/m ] = 0.3[T]\n",
        "\n",
        "w= 2*np.pi/(mean_wave_lenght/sim.c)\n",
        "\n",
        "path = \"C:\\maxwell-LLG\\ws\\simulation_result\\Full_Width_Pulse\\\\\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# besic stuff\n",
        "time_cycal= mean_wave_lenght/sim.c\n",
        "dz = 2e-9/8\n",
        "dt = dz/(2*sim.c)\n",
        "\n",
        "# matiral length according to arcticle\n",
        "magntic_steps = 10e-9//dz\n",
        "conductive_steps = 2e-9//dz\n",
        "\n",
        "# pulse properties\n",
        "sefe_start = 3\n",
        "sigma_pulse = 0.5* (np.log(2)**-0.5) * FWHM\n",
        "peak_enter_time= sefe_start * sigma_pulse\n",
        "fie = np.pi/2\n",
        "\n",
        "#material properties\n",
        "magntic_name = [\"Co\", \"Fe\", \"Ni\"]\n",
        "conductive_name = [\"Au\", \"Pt\"]\n",
        "\n",
        "magntic_eps = [Co_er, Fe_er, Ni_er ]\n",
        "conductive_eps = [  Au_er, Pt_er]\n",
        "\n",
        "magntic_sigma = [Co_sigma, Fe_sigma, Ni_sigma ]\n",
        "conductive_sigma = [ Au_sigma, Pt_sigma]\n",
        "\n",
        "ms0 = 3e5*np.array([1, 0, 0 , 0 ,0, 0.001]).reshape((2,3))\n",
        "\n",
        "#simulation building blocks\n",
        "z1 = 8\n",
        "# z1 = 20\n",
        "z_end = int(z1+ magntic_steps + conductive_steps)\n",
        "z_indexes = [z1, int(z1+ magntic_steps), z_end ]\n",
        "\n",
        "\n",
        "save_loc = np.arange(z1-1, z_end+1)\n",
        "save_loc[0] = 4\n",
        "save_time= []\n",
        "\n",
        "\n",
        "void_steps = 2*z1\n",
        "\n",
        "exit_steps = int(time_cycal/ dt)\n",
        "\n",
        "\n",
        "# we run in sorter time but this what we need:\n",
        "simulation_time = int(2.9*(peak_enter_time//dt + void_steps +4* (magntic_steps + conductive_steps)) + exit_steps)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gg0fmCxbJorA"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "z_ind = [7,100,555]\n",
        "e_r = [1,1,1]\n",
        "sigma = [1.7e7,1e7,1.4e7] # Co, Iron, Nical\n",
        "alpha = {\"Co_Au\" : 0.02, \"Co_Pt\" : 0.025 , \"Fe_Au\": 0.02, \"Fe_Pt\" : 0.025, \"Ni_Au\": 0.05, \"Ni_Pt\" : 0.06}\n",
        "m0 =\n",
        "\n",
        "\n",
        "\n",
        "def simulation(z_ind: list[int], e_r : list[float], sigma: list[float], alpha: float, m0: np.array,\n",
        "               max_E: float, fea : float, FWHM: float,\n",
        "               save_location, save_time, close_system: bool,\n",
        "               dt: float, simulation_time_steps: int, lamda = 800e-9 , teta = 0, safety_start = 4, time_interval = 1):\n",
        "    \"\"\"\n",
        "    inputs-\n",
        "    :param z1: start index of material\n",
        "    :param z2: end index of material\n",
        "    :param e_r:  relative permittivity\n",
        "    :param sigma: condactivity of matiral [Oham/m]\n",
        "    :param alpha: deeiha param of moments\n",
        "    :param m0: initial BIG MAGNETIZATION (sum of moments) configuration in [x,y,z] -> vector size 3\n",
        "    :param max_E: max value of the fileds [A/m]\n",
        "    :param fea: phase defernt betwin E_x and E_y\n",
        "    :param FWHM: the whith of the gausian , time when the pulse is greater than half max power [sec].\n",
        "    :patm save_location: interbel of index in space to save all value in the for all time.\n",
        "    :patm save_time: interbel of index in time to save all value at the intaer space.\n",
        "    :param close_system: wether will use the reflection of M on H on E or not.\n",
        "    :param dt: time step size [s]\n",
        "    :param simulation_time_steps: numer for time steps to do [int]\n",
        "    :param lamda: amplifid wave lenght [m]\n",
        "    :param teta: angle of the central axis of the polarization [rad]\n",
        "\n",
        "    :return: two list in len 3\n",
        "        first list - save parmaters in all space in the save_time stepes\n",
        "        secnd list - saved paarmates in all time in the seve_location ind on space\n",
        "        parm are: [H, E, msi ] ( msi given only in the relvent space if axis)\n",
        "                    all of them in the shep of [time_step]* [space_step]* [3 demntion]\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    # system defntion\n",
        "    dz = 2*c *dt\n",
        "    lenz= z_ind[-1] + int(lamda/dz)\n",
        "\n",
        "\n",
        "    # matrial proprty\n",
        "    const_for_les_E = np.ones(lenz-1)\n",
        "    const_for_H = 0.5*np.ones(lenz-1)\n",
        "    for i in range(len(e_r)):\n",
        "        eps_r = np.ones(z_ind[i+1] - z_ind[i])\n",
        "        eps_r += (e_r[i]-1)\n",
        "        eaf = dt/2/eps* (sigma[i]) /eps_r\n",
        "        const_for_les_E[z_ind[i]:z_ind[i+1]] = ((1-eaf)/(1+eaf))\n",
        "        const_for_H[z_ind[i]:z_ind[i+1]] = (0.5/eps_r/(1+eaf))\n",
        "\n",
        "    # plase for run the symolation\n",
        "    pulse = pulse_gen(max_E, fea, FWHM, dt, lamda, teta, safety_start)\n",
        "\n",
        "    # defing the worke spaec for the simltion\n",
        "    E_next= np.zeros((lenz, 3)).astype(complex)\n",
        "    E_current= np.zeros((lenz, 3)).astype(complex)\n",
        "    right_boundry = [np.zeros((3)), np.zeros((3))]\n",
        "    left_boundry= [np.zeros((3)), np.zeros((3))]\n",
        "    H_next= np.zeros((lenz, 3)).astype(complex)\n",
        "    H_current= np.zeros((lenz, 3)).astype(complex)\n",
        "\n",
        "    ms_i_current= np.zeros((z_ind[-1] -z_ind[0], 3)) ## in every place there is matirial\n",
        "    ms_i_next= np.zeros((z_ind[-1] -z_ind[0], 3)) ## will be filled in the propogate loop acoording to LLG\n",
        "\n",
        "    # intial the beging magntiztion defending on M0 and the index of matiral\n",
        "    for i in range(len(e_r)):\n",
        "        ms_us = m0[i,:] ## : means i want to see all 3 axiz\n",
        "        st_ind = z_ind[i]- z_ind[0]\n",
        "        end_ind = z_ind[i+1] - z_ind[0]\n",
        "        for k in range(3):\n",
        "            ms_i_current[st_ind:end_ind,k]= ms_us[k]/(end_ind-st_ind)\n",
        "\n",
        "\n",
        "    # defing rutenting array:\n",
        "    # for space indxes\n",
        "    time_save = int(simulation_time_steps/time_interval + 1)\n",
        "    E_space_return = np.zeros((time_save, len(save_location), 2)).astype(complex)\n",
        "    H_space_return = np.zeros((time_save, len(save_location), 2)).astype(complex)\n",
        "    msi_space_return = np.zeros((time_save, z_ind[-1]-z_ind[0],3)).astype(complex)\n",
        "\n",
        "    # for time indxes\n",
        "    E_time_return = np.zeros((len(save_time), lenz, 2)).astype(complex)\n",
        "    H_time_return = np.zeros((len(save_time), lenz, 2)).astype(complex)\n",
        "    msi_time_return = np.zeros((len(save_time), z_ind[-1]-z_ind[0] , 3)).astype(complex)\n",
        "    index_to_save_in =0\n",
        "\n",
        "    # propegate\n",
        "\n",
        "    for n in tqdm(range(0, simulation_time_steps), desc= \"simulation pross: \"):\n",
        "        E_current[ 3,0:2] += pulse(n) # inject the input signal\n",
        "\n",
        "        # set bondry condition for not replction\n",
        "        r = right_boundry.pop(0)\n",
        "        l = left_boundry.pop(0)\n",
        "\n",
        "        E_current[ -1,:] = r # last step the end is r condotion\n",
        "        E_current[0,:] = l # same to left\n",
        "\n",
        "        # H eqution\n",
        "        H_next[1:, 0]= H_current[1:, 0]+ 0.5*(E_current[1:,1] - E_current[:-1, 1] )\n",
        "        H_next[1:, 1]= H_current[1:, 1]- 0.5*(E_current[1:, 0] - E_current[:-1, 0] )\n",
        "        # LLG and cang in the ms_i\n",
        "        LLG_kernel[blocks, threadsperblock](ms_i_current, np.real(H_current[z_ind[0]:z_ind[-1],:]), dt, alpha, ms_i_next)\n",
        "        if close_system: # intagrtion line for close sistem B = H + M\n",
        "            H_next[ z_ind[0]:z_ind[-1], :] += ms_i_current - ms_i_next\n",
        "        # E eqution\n",
        "        E_next[ :-1, 1] = const_for_les_E*E_current[:-1,1] + const_for_H* (H_next[1:,0] - H_next[ :-1, 0])\n",
        "        E_next[ :-1, 0] = const_for_les_E*E_current[:-1, 0] - const_for_H* (H_next[1:, 1] - H_next[ :-1, 1])\n",
        "\n",
        "\n",
        "        # get redy to next time step\n",
        "        right_boundry.append(np.copy(E_current[ -2,:]))\n",
        "        left_boundry.append(np.copy(E_current[ 1,:]))\n",
        "        E_current = np.copy(E_next)\n",
        "        H_current = np.copy(H_next)\n",
        "        ms_i_current = np.copy(ms_i_next)\n",
        "\n",
        "        # save to return\n",
        "        # save picture of parameters in time\n",
        "        if n in save_time:\n",
        "            H_time_return[index_to_save_in, :,:] = H_current[:,:2]\n",
        "            E_time_return[index_to_save_in, :,:] = E_current[:,:2]\n",
        "            msi_time_return[index_to_save_in, :,:] = ms_i_current\n",
        "\n",
        "            index_to_save_in += 1\n",
        "\n",
        "        # save the parameters in speceific location in all times\n",
        "        if not n % time_interval :\n",
        "            p =int(n/time_interval)\n",
        "            H_space_return[p, :, :] = H_current[save_location, :2]\n",
        "            E_space_return[p, :, :] = E_current[save_location, :2]\n",
        "            msi_space_return[p, :, :] = ms_i_current\n",
        "    # time_r = H_time_return, E_time_return, msi_time_return\n",
        "    # spece_r = H_space_return, E_space_return, msi_space_return\n",
        "    all_data = {\n",
        "                \"H times picture\": H_time_return,\n",
        "                \"E times picture\": E_time_return,\n",
        "                \"ms time picture\": msi_time_return,\n",
        "                \"time picture\": save_time,\n",
        "                \"H in locations\": H_space_return,\n",
        "                \"E in locations\": E_space_return,\n",
        "                \"ms in locations\": msi_space_return,\n",
        "                \"locations\": save_location,\n",
        "                \"time intervals\": time_interval,\n",
        "                \"matitral location\": z_ind, \"e_r\" : e_r ,\"conductivity\": sigma, \"gilbert damping factor\": alpha,\"initial magnetization\": m0,\n",
        "                \"max magnetic field\" :max_E ,\"polarization phase\": fea,\"pulse width (FWHM)\": FWHM, \"mean wave lenght\" : lamda,\n",
        "                \"systen status\": close_system, \"dt\": dt, \"safety_start\": safety_start\n",
        "                }\n",
        "    return  all_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YIrPphVBvjhZ",
        "outputId": "9eb71f55-ceda-4bb9-e867-501090e2c0c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "104 µs ± 12.9 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
          ]
        }
      ],
      "source": [
        "%timeit LLG_kernel[blocks,threadsperblock](d_big_arr1, d_big_arr2, dt, alpha, d_res); cuda.synchronize()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jNVhvp7SsFyk",
        "outputId": "1166e8cc-0589-4452-be9e-dace6273efa7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "arr1 [[     0      2      4]\n",
            " [     6      8     10]\n",
            " [    12     14     16]\n",
            " ...\n",
            " [599982 599984 599986]\n",
            " [599988 599990 599992]\n",
            " [599994 599996 599998]]\n",
            "arr2 [[     0      1      2]\n",
            " [     3      4      5]\n",
            " [     6      7      8]\n",
            " ...\n",
            " [299991 299992 299993]\n",
            " [299994 299995 299996]\n",
            " [299997 299998 299999]]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[0.00000e+00, 2.00000e+00, 4.00000e+00],\n",
              "       [6.00000e+00, 8.00000e+00, 1.00000e+01],\n",
              "       [1.20000e+01, 1.40000e+01, 1.60000e+01],\n",
              "       ...,\n",
              "       [5.99982e+05, 5.99984e+05, 5.99986e+05],\n",
              "       [5.99988e+05, 5.99990e+05, 5.99992e+05],\n",
              "       [5.99994e+05, 5.99996e+05, 5.99998e+05]])"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "from numba import cuda, float64, int64\n",
        "import math\n",
        "\n",
        "#physical parameters\n",
        "eps=8.854e-12 #[F/m]\n",
        "miu=4*np.pi*1e-7 #[H/m]\n",
        "c=1/(eps*miu)**0.5\n",
        "heta = (miu/eps)**0.5\n",
        "q = 1.60217646e-19    # Elementary charge [Coulombs]\n",
        "miu = 4 * np.pi * 1e-7    # Magnetic permeability [H/m]\n",
        "g = 2    # Landau factor\n",
        "me = 9.1093821545e-31    # Electron mass [kg]\n",
        "gma_factor = 1\n",
        "gama = gma_factor * g * q / (2 * me)\n",
        "alpha = 0\n",
        "dz = 2e-9/8\n",
        "dt = 2\n",
        "\n",
        "big_arr1 = np.arange(0,2*100000*3,2).reshape((100000, 3))\n",
        "big_arr2 = np.arange(100000*3).reshape((100000, 3))\n",
        "\n",
        "#d_big_arr1 = cuda.to_device(big_arr1)\n",
        "#d_big_arr2 = cuda.to_device(big_arr2)\n",
        "M_norm = np.empty_like(big_arr1)\n",
        "res = np.empty_like(big_arr1)\n",
        "#d_res = cuda.device_array_like(big_arr1)\n",
        "\n",
        "blocks = 16  # Ensure enough blocks to cover the data\n",
        "threadsperblock = 512 # Ensure enough threads to cover the data\n",
        "\n",
        "print(\"arr1\",big_arr1)\n",
        "print(\"arr2\",big_arr2)\n",
        "LLG_step(big_arr1, big_arr2, dt, alpha)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ldcIh2c9vR_4",
        "outputId": "2596f40f-93d9-4312-a801-aac8f3398763"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "68.5 ms ± 6.66 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
          ]
        }
      ],
      "source": [
        "%timeit LLG_step(big_arr1, big_arr2, dt, alpha)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": [],
      "authorship_tag": "ABX9TyPzK3XS77BWAsMNar8a618v",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}